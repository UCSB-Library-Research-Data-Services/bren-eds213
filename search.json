[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bren MEDS 213: Databases and Data Management",
    "section": "",
    "text": "This is an archive of the materials used for a 4-unit, letter-grade course delivered in Spring 2024 as part of the Master of Environmental Data Science (MEDS) program in the Bren School of Environmental Science & Management. It includes PowerPoint presentations, instructor notes, live coding transcripts, supplemental materials and readings, and homework assignments.\nThe goals of the course were to give MEDS students the skills they need to practically, successfully, and ethically manage their data, and to create, manage, and use relational databases where appropriate. Relational database topics went farther than just SQL queries and included a significant unit on data modeling and database constraints and integrity, in addition to advanced database topics such as triggers and indexes and accessing databases from programming environments. The data management portion tied into the students’ capstone projects in a couple places, and included analyzing data from an ethical perspective, creating standards-compliant metadata, and employing data de-identification techniques. The course also included a unit on the Unix command line, with an emphasis on creating reusable Bash scripts, given in the spirit that Bash is a generally useful tool that all data scientists should have at least some familiarity with.\nFor the database portion of the course the Arctic Shorebird Demographics Network dataset, obtained from the Arctic Data Center, was used as a running example. While this dataset is not distributed as a relational database (it is packaged as a set of related CSV files), its structure is highly amenable to a relational approach and provides a realistic example of where and why one would want to use a relational database in the Earth and environmental sciences. It also provides just enough complexity to support realistic and complex queries and views. Note that the dataset used in the course, and included in this archive, is a cleaned-up subset of the full dataset. It is necessarily a subset of the full dataset to keep the size and complexity manageable for pedagogical purposes, and it had to be cleaned up because, unfortunately, the full dataset has many errors that would have precluded creating foreign keys.\nDuckDB is used as the database platform due to its strict implementation to data types that turn out to be a weakness of teaching with SQLlite last year. DuckDB is a fast in-process analytical personal database.\nA class data GitHub repository, linked below, was used as the mechanism for distributing files to students. Each week a new directory of files was added to the repository and the students were asked to pull the repository to their local environment. The repository linked here includes the files for all weeks."
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Bren MEDS 213: Databases and Data Management",
    "section": "",
    "text": "This is an archive of the materials used for a 4-unit, letter-grade course delivered in Spring 2024 as part of the Master of Environmental Data Science (MEDS) program in the Bren School of Environmental Science & Management. It includes PowerPoint presentations, instructor notes, live coding transcripts, supplemental materials and readings, and homework assignments.\nThe goals of the course were to give MEDS students the skills they need to practically, successfully, and ethically manage their data, and to create, manage, and use relational databases where appropriate. Relational database topics went farther than just SQL queries and included a significant unit on data modeling and database constraints and integrity, in addition to advanced database topics such as triggers and indexes and accessing databases from programming environments. The data management portion tied into the students’ capstone projects in a couple places, and included analyzing data from an ethical perspective, creating standards-compliant metadata, and employing data de-identification techniques. The course also included a unit on the Unix command line, with an emphasis on creating reusable Bash scripts, given in the spirit that Bash is a generally useful tool that all data scientists should have at least some familiarity with.\nFor the database portion of the course the Arctic Shorebird Demographics Network dataset, obtained from the Arctic Data Center, was used as a running example. While this dataset is not distributed as a relational database (it is packaged as a set of related CSV files), its structure is highly amenable to a relational approach and provides a realistic example of where and why one would want to use a relational database in the Earth and environmental sciences. It also provides just enough complexity to support realistic and complex queries and views. Note that the dataset used in the course, and included in this archive, is a cleaned-up subset of the full dataset. It is necessarily a subset of the full dataset to keep the size and complexity manageable for pedagogical purposes, and it had to be cleaned up because, unfortunately, the full dataset has many errors that would have precluded creating foreign keys.\nDuckDB is used as the database platform due to its strict implementation to data types that turn out to be a weakness of teaching with SQLlite last year. DuckDB is a fast in-process analytical personal database.\nA class data GitHub repository, linked below, was used as the mechanism for distributing files to students. Each week a new directory of files was added to the repository and the students were asked to pull the repository to their local environment. The repository linked here includes the files for all weeks."
  },
  {
    "objectID": "index.html#instructors",
    "href": "index.html#instructors",
    "title": "Bren MEDS 213: Databases and Data Management",
    "section": "Instructors",
    "text": "Instructors\n\nJulien Brun (jb160@ucsb.edu)\nGreg Janée (gjanee@ucsb.edu)\nRenata Curty (rcurty@ucsb.edu)"
  },
  {
    "objectID": "index.html#teaching-assistant",
    "href": "index.html#teaching-assistant",
    "title": "Bren MEDS 213: Databases and Data Management",
    "section": "Teaching assistant",
    "text": "Teaching assistant\n\nJamie Miller (jkmiller@ucsb.edu)"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Bren MEDS 213: Databases and Data Management",
    "section": "Schedule",
    "text": "Schedule\n\nClass: Monday & Wednesday 9:30-10:45 am (NCEAS)\nDiscussion - session 1: Thur 1-1:50PM, Bren Hall 1510\nDiscussion - session 2: Thur 2-2:50PM, Bren Hall 1510\nOffice hours: Monday 11-12 pm (NCEAS)"
  },
  {
    "objectID": "index.html#course-content",
    "href": "index.html#course-content",
    "title": "Bren MEDS 213: Databases and Data Management",
    "section": "Course content",
    "text": "Course content\nSyllabus\nInstalling SQLite\nResources\nClass data GitHub repository"
  },
  {
    "objectID": "index.html#modules",
    "href": "index.html#modules",
    "title": "Bren MEDS 213: Databases and Data Management",
    "section": "Modules",
    "text": "Modules\n\n\n\nWeek\nTopic/Content\n\n\n\n\n1\nRelational databases and data modeling\n\n\n2\nAnalyzing & cleaning the bird dataset (from csv)\n\n\n3\nIntrodutcion to SQL & DuckDB\n\n\n4\nImporting data in the database\n\n\n5\nAnalyzing the bird database using SQL\n\n\n6\nUsing R & python to query databases\n\n\n7\nDocumenting your work: metdata & computing environment\n\n\n8\nSensitive data\n\n\n9\nEthical & responsible data mgnt\n\n\n10\nData licensing and publication"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Course syllabus",
    "section": "",
    "text": "This course will teach students the fundamentals of relational databases and data management. Students will learn the principles of database modeling and design and gain practical experience applying SQL (Structured Query Language) to manage and manipulate relational databases. The course also introduces the role and application of data documentation and metadata standards for interoperability and effective data management. By the end of the course, students will be equipped to make informed decisions about managing databases and data ethically and responsibly, focusing on issues such as bias, data privacy, sharing, ownership, and licensing."
  },
  {
    "objectID": "syllabus.html#overview",
    "href": "syllabus.html#overview",
    "title": "Course syllabus",
    "section": "",
    "text": "This course will teach students the fundamentals of relational databases and data management. Students will learn the principles of database modeling and design and gain practical experience applying SQL (Structured Query Language) to manage and manipulate relational databases. The course also introduces the role and application of data documentation and metadata standards for interoperability and effective data management. By the end of the course, students will be equipped to make informed decisions about managing databases and data ethically and responsibly, focusing on issues such as bias, data privacy, sharing, ownership, and licensing."
  },
  {
    "objectID": "syllabus.html#learning-objectives",
    "href": "syllabus.html#learning-objectives",
    "title": "Course syllabus",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nUnderstand the fundamental principles of relational databases and relational data modeling, including table structures, primary and foreign keys, relationships between tables, and data normalization.\nUnderstand how to use the Unix command line and how manage DuckDB databases from the command line.\nUse SQL to retrieve, manipulate, and manage data stored in a relational database.\nDemonstrate proficiency in querying, filtering, sorting, and programmatically accessing and interacting with relational databases from R and Python.\nBecome familiar with advanced database topics such as concurrency, transactions, indexing, backups, and publication.\nUnderstand the role of good data documentation and metadata standards for interoperability, effective data management, and reproducibility.\nOperationalize the FAIR principles into data management practices.\nProduce a metadata record in EML (Ecological Metadata Language) and apply metadata crosswalks to programmatically convert metadata schemas.\nUnderstand the ethics of sensitive data and how to de-identify sensitive data.\nEvaluate ethical and responsible data management practices, including bias, data privacy, sharing, ownership, and licensing issues."
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "Course syllabus",
    "section": "Schedule",
    "text": "Schedule\n\nClass: Monday & Wednesday 9:30-10:45 am (NCEAS)\nDiscussion - session 1: Thur 1-1:50PM, Bren Hall 1510\nDiscussion - session 2: Thur 2-2:50PM, Bren Hall 1510\nOffice hours: Monday 11-12 pm (NCEAS)"
  },
  {
    "objectID": "syllabus.html#modules",
    "href": "syllabus.html#modules",
    "title": "Course syllabus",
    "section": "Modules",
    "text": "Modules\n\n\n\nWeek\nTopic/Content\n\n\n\n\n1\nRelational databases and data modeling\n\n\n2\nAnalyzing & cleaning the bird dataset (from csv)\n\n\n3\nIntrodutcion to SQL & DuckDB\n\n\n4\nImporting data in the database\n\n\n5\nAnalyzing the bird database using SQL\n\n\n6\nUsing R & python to query databases\n\n\n7\nDocumenting your work: metdata & computing environment\n\n\n8\nSensitive data\n\n\n9\nEthical & responsible data mgnt\n\n\n10\nData licensing and publication\n\n\n\n*Schedule subject to change."
  },
  {
    "objectID": "syllabus.html#course-assessment",
    "href": "syllabus.html#course-assessment",
    "title": "Course syllabus",
    "section": "Course assessment",
    "text": "Course assessment\nYour performance in this course will depend 90% on weekly homework assignments and quizzes and 10% on participation. There will be no graded exercises or homework the last week."
  },
  {
    "objectID": "syllabus.html#attendance-and-homework-policy",
    "href": "syllabus.html#attendance-and-homework-policy",
    "title": "Course syllabus",
    "section": "Attendance and homework policy",
    "text": "Attendance and homework policy\nAttendance is required. Material will be given in class that is not covered by slides or background readings.\nHomework is expected to be turned in on time. A generous amount of time will be given to complete assignments. Do not wait until the last minute to work on homework in case something unexpected comes up. Homework turned in late will be docked 25% per day."
  },
  {
    "objectID": "syllabus.html#code-of-conduct",
    "href": "syllabus.html#code-of-conduct",
    "title": "Course syllabus",
    "section": "Code of conduct",
    "text": "Code of conduct\nAll students are expected to read and comply with the UCSB Student Conduct Code. We expect cooperation from all members to help ensure a welcoming and inclusive environment for everybody. We are determined to make our courses welcoming, inclusive and harassment-free for everyone regardless of gender, gender identity and expression, race, age, sexual orientation, disability, physical appearance, or religion (or lack thereof). We do not tolerate harassment of class participants, teaching assistants, or instructors in any form. Derogatory, abusive, or demeaning language or imagery will not be tolerated."
  },
  {
    "objectID": "syllabus.html#student-support",
    "href": "syllabus.html#student-support",
    "title": "Course syllabus",
    "section": "Student support",
    "text": "Student support\nWe understand that ongoing crises impact students differently based on experiences, identities, living situations and resources, family responsibilities, and unforeseen challenges. We encourage you to prioritize your well-being. We are here to help you reach your learning and career goals. You are always welcome to reach out to our teaching team so that we can best support you. Please see the UCSB Campus Resource Guide for campus student support and services."
  },
  {
    "objectID": "syllabus.html#disabled-students-program",
    "href": "syllabus.html#disabled-students-program",
    "title": "Course syllabus",
    "section": "Disabled students program",
    "text": "Disabled students program\nStudents with disabilities and/or alternative learning needs are encouraged to work with the Disabled Students Program at UCSB to ensure we can best support your learning and success."
  },
  {
    "objectID": "installing-duckdb.html",
    "href": "installing-duckdb.html",
    "title": "Installing SQLite",
    "section": "",
    "text": "SQLite (the sqlite3 command) comes already installed on Mac and Linux machines. However even with those machines some configuration of SQLite will be required for this course, see below."
  },
  {
    "objectID": "installing-duckdb.html#windows-installation",
    "href": "installing-duckdb.html#windows-installation",
    "title": "Installing SQLite",
    "section": "Windows installation",
    "text": "Windows installation\nIf not already installed, install Git for Windows. Instructions and some good default settings can be found here. Note that it is not necessary to install Git or Bash in order to run SQLite on Windows; SQLite can be run from the desktop or from the DOS command prompt. But for this course we will be using Bash.\nNext, install SQLite from https://www.sqlite.org/download.html. Select, under “Precompiled Binaries for Windows,” the download that includes “A bundle of command-line tools for managing SQLite database files.” Extract the download into a directory C:\\sqlite. The SQLite command line tool will be located at a path resembling C:\\sqlite\\sqlite-tools-win32-x86-3410200\\sqlite3.exe. Instructions for further setting up to run SQLite under the DOS command prompt can be found here if you’re interested, but we won’t be needing that.\nTo be able to easily run SQLite from any directory, update your Bash path by editing ~/.bash_profile. If you’re not familiar with Unix text editors, trying using nano from the Bash prompt:\ncd ~\nnano .bash_profile\nIf your sqlite3.exe is located in C:\\sqlite\\sqlite-tools-win32-x86-3410200, the equivalent Unix pathname is /c/sqlite/sqlite-tools-win32-x86-3410200. You want to add this directory (or whatever yours is called) to your PATH environment variable. To do so, add the following line to your .bash_profile:\nexport PATH=$PATH:/c/sqlite/sqlite-tools-win32-x86-3410200\nAgain, your pathname may differ depending on where sqlite3.exe is located.\nWith that set up, after starting a new Bash session you will be able to run SQLite from any directory simply by typing:\nsqlite3"
  },
  {
    "objectID": "installing-duckdb.html#configuring-sqlite3",
    "href": "installing-duckdb.html#configuring-sqlite3",
    "title": "Installing SQLite",
    "section": "Configuring sqlite3",
    "text": "Configuring sqlite3\nFor this class it will be necessary to configure SQLite every time it runs. This is accomplished by created a file ~/.sqliterc. So, from Bash:\ncd ~\nnano .sqliterc\nIn this file put the following two lines:\n.mode box\nPRAGMA foreign_keys = ON;\nThe first line turns on some nice display formatting. The second line is necessary to enable certain SQL functionality this is disabled by default."
  },
  {
    "objectID": "installing-duckdb.html#confirming-that-sqlite-works",
    "href": "installing-duckdb.html#confirming-that-sqlite-works",
    "title": "Installing SQLite",
    "section": "Confirming that SQLite works",
    "text": "Confirming that SQLite works\nFrom any directory, you should be able to run sqlite3, issue a “PRAGMA foreign_keys” command that returns 1, and get output resembling below.\nbash% sqlite3\n-- Loading resources from C:\\Users\\user\\.sqliterc\nSQLite version 3.39.4 2022-09-29 15:55:41\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\nsqlite&gt; PRAGMA foreign_keys;\n┌──────────────┐\n│ foreign_keys │\n├──────────────┤\n│ 1            │\n└──────────────┘\nsqlite&gt; .exit\nbash%"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Burnette. (2022). Managing environmental data: principles, techniques, and best practices. CRC Press. https://search.library.ucsb.edu/permalink/01UCSB_INST/1aqck9j/alma9917095897506531\nChapman, AD, & Grafton, O. (2008). Guide to Best Practices for Generalising Sensitive Species-Occurrence Data (v1.0). https://doi.org/10.15468/doc-b02j-gt10\nCrystal-Ornelas, R., Varadharajan, C., O’Ryan, D., Ramírez-Muñoz, J., Jones, M. B., Lehnert, K. A., … & Servilla, M. (2022). Enabling FAIR data in Earth and environmental science with community-centric (meta)data reporting formats. Scientific Data, 9(1), 700. https://doi.org/10.1038/s41597-022-01606-w\nJones, M. B., O’Brien, M., Mecum, B., Boettiger, C., Schildhauer, M., Maier, M., Whiteaker, T., Earl, S., & Chong, S. (2019). Ecological Metadata Language version 2.2.0. KNB Data Repository. https://doi.org/10.5063/F11834T2\nLabastida, I., & Margoni, T. (2020). Licensing FAIR Data for Reuse. Data Intelligence, 2(1-2), 199-207. https://doi.org/10.1162/dint_a_00042\nMcGovern, A., Ebert-Uphoff, I., Gagne, D., & Bostrom, A. (2022). Why we need to focus on developing ethical, responsible, and trustworthy artificial intelligence approaches for environmental science. Environmental Data Science, 1, E6. https://doi.org/10.1017/eds.2022.5\nRecknagel, F., & Michener, W. K. (Eds.). (2018). Ecological informatics: Data management and knowledge discovery (3rd ed.). Springer."
  },
  {
    "objectID": "resources.html#bibliography",
    "href": "resources.html#bibliography",
    "title": "Resources",
    "section": "",
    "text": "Burnette. (2022). Managing environmental data: principles, techniques, and best practices. CRC Press. https://search.library.ucsb.edu/permalink/01UCSB_INST/1aqck9j/alma9917095897506531\nChapman, AD, & Grafton, O. (2008). Guide to Best Practices for Generalising Sensitive Species-Occurrence Data (v1.0). https://doi.org/10.15468/doc-b02j-gt10\nCrystal-Ornelas, R., Varadharajan, C., O’Ryan, D., Ramírez-Muñoz, J., Jones, M. B., Lehnert, K. A., … & Servilla, M. (2022). Enabling FAIR data in Earth and environmental science with community-centric (meta)data reporting formats. Scientific Data, 9(1), 700. https://doi.org/10.1038/s41597-022-01606-w\nJones, M. B., O’Brien, M., Mecum, B., Boettiger, C., Schildhauer, M., Maier, M., Whiteaker, T., Earl, S., & Chong, S. (2019). Ecological Metadata Language version 2.2.0. KNB Data Repository. https://doi.org/10.5063/F11834T2\nLabastida, I., & Margoni, T. (2020). Licensing FAIR Data for Reuse. Data Intelligence, 2(1-2), 199-207. https://doi.org/10.1162/dint_a_00042\nMcGovern, A., Ebert-Uphoff, I., Gagne, D., & Bostrom, A. (2022). Why we need to focus on developing ethical, responsible, and trustworthy artificial intelligence approaches for environmental science. Environmental Data Science, 1, E6. https://doi.org/10.1017/eds.2022.5\nRecknagel, F., & Michener, W. K. (Eds.). (2018). Ecological informatics: Data management and knowledge discovery (3rd ed.). Springer."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]